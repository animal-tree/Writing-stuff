**The actual derivation would be sampling particles from Gaussians and optimizing their branching-probability wave-duality paths, from each local collision as a convolved function, to each non-local trajectory as a probabilistic variational optimization like beam search, but I'm sick and tired of thinking about this.**

---

I also have a classical description for gravity theorized.

...

Dark matter bouncing between two objects creates a pressure gradient in surrounding dark matter. A “bend” in spacetime, literalized. Dark matter interacts with mass to change its velocity only under some conditions. One of those is the pressure gradient created by that back and forth bounce. You can imagine it as a smiley face bouncing back and forth between two unhappy bodies. Besides dark matter, this only happens as 2-way or more interaction between masses, and then N-way with surrounding dark matter. Surounding dark matter. Mass A. And Mass B. That's why it's illuded physicists. It's an N-body problem. Velocity changes as a result of dark matter bouncing between two masses and causing a dent and pressure gradient in surrounding dark matter, under specific conditions.

The answer to why this happens in the first place is starting to flesh out below. And the math about the specific conditions (there are multiple local "rules" that can be conceived) to satisfy a local-"corpuscular" classical description are in my journal somewhere and I can probably reconstruct them.

---

Mysteries

- Gravity / dark matter: self-creation / bouncing-happy-smiley-faces
- Relativity: Yes, from a belief perspective [with photon as choice of carrier signal for inter-body communication](Stuff10-Observation.md)
- Wave-particle duality: optimization
- Rules: [limited resources of Qualia/observation constrained to time](All-science-reduces-to-the-sensory.md)

Also subparts making up people that I call archetypes, literally consciousnesses within consciousnesses. Communicating. Through local symbolic languages, sometimes cryptic. A superconsciousness, collective “governance”, not necessarily a good one, and so on.

If there isn’t a God, there most certainly can be, from what I’ve seen. Via collective [consciousness](Stuff22-What-is-Consciousness?.md) intelligence and potentially actual control to some variational degree of physical matter, the modulation of which could be a communication mechanism with people, assuming we’ve evolved a symbiosis for it.

And that’s a lot of what I know! In vague condensed form, reduced from stacks of composition notebooks and journals. With math.

---

# Maybe more fun

I'm gonna try to derive it deductively starting with cosmogenesis and some clean simple Identity functions.

## Observation and Qualia

How can nothing bring rise to something, mathematically? We think we have solved the confounding "cosmogenesis" riddle with the use of >3-way mathematical implications in the definition of definition. Correct us if we're wrong.

First, let us define a symbol for our "nothing". $\emptyset$. Very good, now:

---

**Axiom 1:** $\exists \emptyset, \mathrm{I}$.

---

The empty set, "nothing" and the Identity function, exist. This may or may not be debatable, whether it should be an axiom or a theorem, since by definition:

$\mathrm{I}(\emptyset) = \emptyset$

is not self-contradicting. Can a function "exist"?

To that end, we will argue yes, by noting the function of observation. "I observe." Whatever this function is, perhaps we can equate it to $\mathrm{I}$ the Identity function. By analogy, if not, in a moment... literally.

For that matter, an elementary particle, something that is *presumed*, axiomatically, to exist without justifying cause, hence "elementary", is itself a function with a quantum state that affects and determines the functions of other elementary particles. Perhaps... in a moment... we will equate it to $\mathrm{I}$ as well.

This would be mathematically impressive if we did so without further assumptions, using only the rules of mathematical deduction!

Hopefully, if that motivates the exploration, let's proceed. i.e. 3 goals:

(1) a logically consistent "cosmogenesis".
(2) observation, and its substituents, Qualia.
(3) elementary particles.

From just the established axiom: $\exists \emptyset, \mathrm{I}$. Using only the fair-game rules of mathematical deduction.

We may need some more axioms along the way, but for now, let's see how far we can get with just what we have.

---

**Definition 1:** Observation. 

Let $o = \mathrm{I}$ be observation. Every variable equivalent:

$\mathrm{I_1} = \mathrm{I_2} = \cdots = o$

Furthermore, $o = \mathrm{I}_I, \forall I \subseteq \mathbb{N}$.

These are just variables to describe the same constant.

---

Since $\exists \mathrm{I}$, we can now play around with $\mathrm{I}(\mathrm{I}) = \mathrm{I}$ and variations of it using Qualia $\mathrm{I_i}(\mathrm{I_j}) = \mathrm{I_j}$.

For instance, we have:

$\mathrm{I_i}(\mathrm{I_j}) = \mathrm{I_j} = \mathrm{I_k} = \mathrm{I_i}(\mathrm{I_k})$,

suggesting a simple equivalence with no secret-catch. Let's however unfold this:

$\mathrm{I_i}(\mathrm{I_j}) \leftrightarrow \mathrm{I_j} \leftrightarrow \mathrm{I_k} \leftrightarrow \mathrm{I_i}(\mathrm{I_k})$

From here, through the use of cycles, we will see how "something" can arise from nothing. In fact, this is at the basis of all math. Every deduction is premised on *defined* axioms and implications. The theorems derived from them all reduce to "by definition" and yet many branching paths and interpretations, useful ones to the real world, emerge from exploring nothing more, mathematically speaking, than definition. "What is definition?", philosophically speaking. Perhaps it is something that arises from the real world, the existence of many within equivalence.

One way to satisfy the earlier defined equivalence is:

$\mathrm{I_i}(\mathrm{I_j}) \rightarrow \mathrm{I_j} \rightarrow \mathrm{I_k} \rightarrow \mathrm{I_i}(\mathrm{I_k})$

and

$\mathrm{I_i}(\mathrm{I_j}) \leftarrow \mathrm{I_j} \leftarrow \mathrm{I_k} \leftarrow \mathrm{I_i}(\mathrm{I_k})$

and perhaps multi-node arrows going in-between to create a fully-connected graph. But minimally, a simple cycle would suffice:

$\mathrm{I_i}(\mathrm{I_j}) \rightarrow \mathrm{I_j} \rightarrow \mathrm{I_k} \rightarrow \mathrm{I_i}(\mathrm{I_k})$

and

$\mathrm{I_i}(\mathrm{I_j}) \leftarrow \mathrm{I_j} \leftarrow \mathrm{I_k} \leftarrow \mathrm{I_i}(\mathrm{I_k})$.

The cycle justifies all of the other arrows and satisfies the definition of equivalence. Extra implications, while theoretically optional, are not needed. We could from here, create causality. 

Under the ambiguities that remain, $\mathrm{I}$ can be defined different behaviors in addition to the ones already defined. In fact they must be, for mathematical soundness. For example:

does $\mathrm{I_i}(\mathrm{I_j}) \rightarrow \mathrm{I_i}$?

The answer is yes, but not *before* 

$\mathrm{I_i}(\mathrm{I_j}) \rightarrow \mathrm{I_j} \rightarrow \mathrm{I_i}$.

Unless the identity graph were fully-connected. But, under the mathematical ambiguity, let us define equivalence here:

---

**Definition 2:** Disambiguated Qualia uniqueness.

$\mathrm{I}_I$ are not substitutable in the domain of the function that defines their equivalence.

$\mathrm{I_\mathit{I}}(\mathrm{I_\mathit{J}}) \not\rightarrow_1 \mathrm{I_\mathit{K}} \vert J \neq K$.

$\mathrm{I_\mathit{I}}(\mathrm{I_\mathit{J}})$ does *not* imply $\mathrm{I_\mathit{K}}$ in one deductive step,

where $\rightarrow_n$ denotes the number of deductive steps $n \in \mathbb{N}, J \neq K$. 

---

**Definition 3:** Qualia and qualia.

$\mathbb{Q} = \mathrm{I}_I \vert I \subseteq \mathbb{N}$ is Qualia, where any $I \subseteq \mathbb{N}$ will be referred to as qualia, lowercase.

These are just variables to describe the same constant.

qualia are the "distinguishing traits".

$\mathbb{N}$ are not strictly the natural numbers and may not be infinite.

---

In other words, qualia are distinguishable in the domain of observers in Qualia.

Notice there is no contradiction to this in the definition of equivalence or Qualia/qualia or the function of $o = \mathrm{I}$.

---

**Theorem 1:** Furthermore, $\exists \mathbb{Q}$.

**Proof:** By Axiom 1 and Definition 1, $\exists o$. 

$o = \mathrm{I}_I, \forall I \in \mathbb{N}, I \subseteq \mathbb{N}$.

Then $\exists \mathrm{I}_I, \forall I \subseteq \mathbb{N}$.

By Axiom 1 (using the empty set), $\exists \mathbb{Q}$. $\square$

---

"Does a set "exist"?" That's another question we can ask. Mathematically, it is a convenient organizing tool for describing many subparts at once. Each of the subparts exists by equivalence to $I$, therefore $\exists \mathbb{Q}$, by which we mean: the subparts exist.

Qualia, interestingly, is proof that something can emerge from almost-nothing.

Curvature, as we shall see, becomes a necessary property to such an existence.

## Idk

So a lot of room has been opened up for defining previously-ambiguous regions of deduction that all hold equally well mathematically. The "implication graph" emerging as a multi-interpretable data structure just from simple equivalence is a big deal. It means we can now, without loss of generality, explore many definitions of its construction. Perhaps infinite possible ones. The only rule is that there must be at least one cycle back to the origin, eventually, from every node, in order to satisfy equivalence. We have thus expanded equivalence into (a) causality and (b) self-creation.

## Teleology

I mentioned wave-particle duality as beam-search-like optimization strategy with truncation for truncating improbable branches (those that haven't been "observed" / collided with as much), but optimization assumes an objective being optimized. That objective is qualia. See here for example, expanding from the above deduction:

**Definition 4:** Some qualia feel better than others.

In multi-branch choices of implication, we select the $K$ that brings us closest to some rich qualia, $L$.

$\mathrm{I_I}(\mathrm{I_J}) \rightarrow \mathrm{I_J} \rightarrow \mathrm{I_K}$

We have an objective:

$K =  \max\limits_K \mathbf{P}(\mathrm{I}_L \vert \mathrm{I}_K)$,

where $L \subseteq \mathbb{N}$ is some objectively good feeling.

---

It's a definition since "qualia" is not a mathematical object that's been defined before and these areas of math are otherwise ambiguous. Whether that's how the universe works, it can be an axiom or not. "I observe" / "I feel" are proven statements, so somewhere in the universe these dynamics exist. If they happen to derive the actual properties and behaviors of the universe, then we can say, yeah, that's probably it. I don't see any other non-religious theories for cosmogenesis. The Big Bang theory is not an origin theory. It's a microseconds-from-origin theory. No one knows how that condensed cosmic soup emerged into existence, or why.

Notice so far these are all just disambiguating definitions of equivalence, including what might motivate the selection of any $K$ at all. If you believe in definition or "equivalence", then somewhere in the definitions of those is ambiguity that we are now compartmentalizing into a data structure of Qualia. Other ways to disambiguate it exist, but have not been proposed.

The goal is to reach a classical description of the universe, with its mysterious quantum and relative phenomena explained by (a) optimization needs, and (b) belief/perspective systems. One such need, for any causality to exist at all is self-cyclicality (self-creation), otherwise causality would contradict itself for not having a cause. Above we derive that, literally, and hint that this cyclicality property necessary in self-consistent causal spacetime is connected to curvature, and might be the reason for the classical interpretation of that curvature, proposed here, as an N-body interaction with dark matter.

A teleological explanation isn't new to physics. After all, the Hamiltonian can be thought of as a teleological explanation, in a sense. But this one more explicitly invokes an "objective". Ideas like "path of least action" almost imply an objective, but, as we've seen, have alternative more causal ways of interpreting. Similarly, any such teleological objective proposed here can also have an alternate perspective such as, evolutionary emergence: what sort of teleology would prime a universe for survival in the space of all possible universes that could emerge in our ambiguous deductive equivalence computation grammar?

---

To get to that we need at least a Turing machine deducible from these ambiguities of equivalence. Thus far, I believe, we have a [finite automaton](https://en.wikipedia.org/wiki/Deterministic_finite_automaton) $M = (\mathbb{Q}, \mathbb{N}, \delta, \mathrm{I}_1, \mathrm{I}_1)$ with unspecified teleological-optimization of transition function $\delta$. Getting there shouldn't be [too hard](https://www.cs.utep.edu/vladik/2018/tr18-54.pdf), but we may need infinity on our side.

Here is an example of a finite automaton that allows even numbers followed by odd numbers, alternating:

$\mathrm{I_1} \rightarrow \mathrm{I_\mathbb{\mathrm{i} \sim N_\text{even}}} \rightarrow \mathrm{I_1}(\mathrm{I_i}) \rightarrow \mathrm{I_i} \rightarrow \mathrm{I_\mathbb{\mathrm{i} \sim N_\text{odd}}} \rightarrow \mathrm{I_1}(\mathrm{I_i}) \rightarrow \mathrm{I_i} \rightarrow \mathrm{I_1}$.

Hence even numbers are always "observed" before odd numbers and they cycle. Observations are the alphabet, the observers are states. Note: we have not defined the range of observation yet, so $M$ has put $\mathbb{N}$ in its place, suggesting the observers output qualia.

To get this into arbitrary finite automata we may need a clause that says "eventually" the sink state will be the origin. Meanwhile new states can be created or cycled through to simulate a sink state into the infinitum. Thus the universe does not end for such an automaton, but expands.

The proof of this is beyond the scope of my brain.

However, via multiple branches from the same state allowed, this seems trivial. Indeed, branching/re-branching with infinity to account for the sink state makes this a finite automata-capacity machine. Grammatically, this can be considered God's first word.

For example, we can sink after two digits as such:

$\mathrm{I_1} \rightarrow \mathrm{I_\mathbb{\mathrm{i} \sim N_\text{even}}} \rightarrow \mathrm{I_1}(\mathrm{I_i}) \rightarrow \mathrm{I_i} \rightarrow \mathrm{I_\mathbb{\mathrm{i} \sim N_\text{odd}}} \rightarrow \mathrm{I_1}(\mathrm{I_i}) \rightarrow \mathrm{I_i} \rightarrow_\infty \mathrm{I_1}$,

where $\rightarrow_n$, defined in Definition 2, means "implied after $n$ deductive steps."

Or if that doesn't satisfy you, then allow $n$ to be a really, really long time.

$>$ 13 billion years and counting for example.

---

Constructing a read/writable Turing-machine tape is also quite easy, given the expressiveness of our language. In one sentence that language is: "Any implication graph that connects every node, by one or more deductive step, including the origin, with a position on that graph demarking "now."" That means, as time expands and the "now" head (analogous to a Turing machine head) moves forward in time, the implication graph downstream can expand with extra nodes distancing "now", the current deductive step, from the origin. Each now point can branch rings describing X-coordinates, Y-coordinates, and Z-coordinates, whose qualia from step to step can update as they are re-copied and implied to with each time increment. These fully-connected coordinate rings, expanding outward with the arrow of time, can denote our Turing-tape, or, more intuitively, space.

However, as the implication graph cycles through the spatial dimensions (or spirals rather), it must land on the "next" deductive step point in time. To keep such a cycle going while connecting its extrema back to the origin requires the expansion of the spacetime dimensions as well since they are intertwined as one arrow.

A 1D universe for example would be a circular spring. As our deductive steps progressed along that spring, to keep from cycling back to the origin, the spring would have to increase in radius proportionally to the amount it increases in length/circumference. Each new ring would have to be bigger to account for the time delay of growing it out in parallel.

Idk, I'm skeptical about this image and the existence of a "now" head assumed in this construct.

Why don't we just define $\mathrm{I}$ exactly as we would an elementary particle, but now we have a reason for believing they could arise axiomatically from "nothing" or a reasonably close conception of it.

> See, as the empty set is the closest symbol to what we can conceptualize as literally "nothing" and the Identity function is, perhaps, at least within reason, an innate natural operator, these are not far stretches as axioms for the origin of something out of nothing. Too simple? Too abstract? Yes. But within the bounds of logical reasoning. We've shown a finite automaton would not be a contradiction to a fairly reasonable conception of a $\emptyset, \mathrm{I}$-dual origin.

I am embaressed by this and wish I could delete it.

But I'm afraid of losing record of the other work that I've done, that I no longer have the motivation or care to write or think about.
