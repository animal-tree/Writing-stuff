"I observe."

Whatever this function is define it as $\mathrm{I}$. Let's give it infinite equivalents, again by definition:

$\mathrm{I}_1 = \mathrm{I}_2 = \cdots$.
 
Each of these exists by definition.

Now apply these observers to each other. $\mathrm{I}_i(\mathrm{I}_j(\mathrm{I}_k)) = (\mathrm{I}_j, \mathrm{I}_k)$.

**Definition 1**: An observer is a function that exists. $\mathrm{I}$.

$\mathrm{I} = \mathrm{I_1} = \mathrm{I_2} = \cdots$

are different variables that we are defining that are equivalent to $\mathrm{I}$, not separate.

**Definition 2**: $\mathbb{Q} = \mathrm{I}_\mathbb{N}$.

where $\mathbb{Q}$ is Qualia, $\mathbb{N}$ is qualia.

$\mathrm{I}_i(\mathrm{I}_I^n(\mathrm{I}_j)) = (\mathrm{I}_I, \mathrm{I}_j)$

where $\mathrm{I}_I^n$ represents composability of $n$ observers $\mathrm{I}_I, I = 1, ..., n$.

Without loss of generality of Definition 1.

---

We will now premise on two possibilities: (1) the existence of causality and (2) no assumption about the existence of causality.

---

### (1) The existence of causality:
#

**Definition**:

$\mathbf{P}((y, h^{(n)}) \sim \mathrm{R}^n(x, h^{(1)}) \vert y) \neq \mathrm{U}$

$x$ is the cause, $y$ is the effect, under some dynamics system $\mathrm{R}$.

For every effect $y$, there is a cause $x$.

$\exists y \rightarrow \exists x \vert x \rightarrow y$

$\mathrm{U}$ is the Uniform distribution.

$n \in \mathbb {N}$, $x \neq y$, and $R \neq \mathrm{I}$.

$h$ is a theoretical memory and global context window to not assume fully-observed Markovian dynamics.

---

**Definitions**: $o = \mathrm{I}_{i \in \mathbb{N}}$ is observation and $\hat{\mathrm{R}} \sim \mathrm{R}$ is a physics model.

**Theorem 1**: Then $\exists \hat{\mathrm{R}} \sim \mathrm{R}$ s.t.

$\mathbf{P}((o, h^{(n)}) \sim \mathrm{\hat{R}}^n(x, h^{(1)})) \neq \mathrm{U}$

**Proof:**

Observation $o$ exists. $\square$

---

**Corrillary 1:** Observation suffices to represent the natural numbers, denoted qualia, above, $\mathbb{N}$.

**Proof**:

1. $\mathrm{I_2}(\mathrm{I_1})$
2. $\mathrm{I_3}(\mathrm{I_2}(\mathrm{I_1}))$
3. $\mathrm{I_4}(\mathrm{I_3}(\mathrm{I_2}(\mathrm{I_1})))$

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\vdots$  

$\square$

**Corrillary 2:** Observation suffices to represent the tape of a Turing machine.

**Proof**: $\mathbb{N}$ suffices to represent binary integers. $\square$

**Theorem 2**: Observation and causality give us a Turing-complete machine.

Since $h$ is a theoretical memory, this gives us a Turing-complete machine. Let

$\mathbf{P}((o, \hat{h}^{(\hat{n})}) \sim \hat{\mathrm{R}}^\hat{n}(\hat{x}, \hat{h}^{(1)})) = 1$

for some samples $\hat{h}^{(1)}, \hat{n}, \hat{x}, \in \mathbb{N}$. Then $\hat{\mathrm{R}}$ is our Turing machine.

In fact, \hat{\mathrm{R}} is a non-deterministic Turing machine if we do not constrain the probability to 1.

$\square$

---

**Theorem:** Causality gives us a cyclical convergence

$\lim_{t \to +\infty} \Omega_t = \Omega_0$

TBA

**Contextualization**



**Proof** (outline)

1. Define causality as a random variable.
2. It's either cyclical or "turtles all the way down."
3. If it's turtles all the way down, then the cause of turtles all the way down is turtles all the way down, making it nevertheless cyclical ("The cause of $\infty$ is $\infty$").

---

**Theorem:** Causality gives us a teleological objective

**Theorem:** Causality implies limited resources
