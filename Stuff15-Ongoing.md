Let's start with nothing.

$\emptyset$.

From nothing, let's build the ground up.

Here's a fact: $\mathrm{I}(\emptyset) = \emptyset$, 

where $\mathrm{I}$ is the Identify function.

And another: $\mathrm{I}(\mathrm{I}) = \mathrm{I}$.

Great, we can now compose them. Let $\mathrm{I}(\mathrm{I}(\cdot))$ represent a $0$ and $\mathrm{I}(\mathrm{I})(\cdot)$ represent a $1$.

Great, we've now emerged representation. $\mathrm{I}(\mathrm{I}(\mathrm{I}(\mathrm{I})(\mathrm{I}(\mathrm{I})(\emptyset))))$ = 011.

Let's endow it with qualitative subscripts. We can express $\mathrm{I}$ in multiple identities:

$\mathrm{I}_1(\emptyset) = \emptyset$, $\mathrm{I}_2(\emptyset) = \emptyset$, $\mathrm{I}_1(\mathrm{I}_2) = \mathrm{I}_2$, ...

$\mathrm{I}_1$ is the Identity function just as much as $\mathrm{I}_2$. We are defining a new set of functionally indistinguishable Identity functions. 

$\mathrm{Q} = \mathrm{I}_\mathbb{N}$

We will refer to this set as Qualia.

---

Since we are within a mathematical system, we also have access to one more axiom: Causality, the rules of deduction. But let us treat it as a hypothetical.

In deduction, every deductive step is defined to have a deductive cause, except the base causes. Those are called axioms, which we have avoided establishing thus far. That is the definition. $\mathrm{I}$ and $\emptyset$ also behave as definitions. $\emptyset$ especially is abstract, representing symbolically "nothing".

But what may be the deductive cause for deduction and the deductive step if it is not assumed as an axiom? Equivalently, "what may cause causality?" Perhaps:

1. It caused itself (it deduces itself)
2. Something else caused it (it is the byproduct of an external mathematical framework)
3. Its existence is unjustified by a cause (it is an axiom)

Since there is no second mathematical system that would not contain itself, and the non-assumption that it is not an axiom, 2 and 3 are impossible. This leaves 1: self-deduction. This deduction must eventually deduce itself.

We can interpret two possible self-deductions:

1. One where the deductive steps are cyclical: $\Omega_T = \Omega_0$ for the number of deductive steps $T$.
2. Or $\lim_{t \to +\infty} \Omega_t = \Omega_0$, an infinite "series", or much like one, where the deductive steps may eventually, in their infinitum, deduce themselves.

Either way, the proof is further constrained. For example, we are not allowed to establish an axiom now that says, "here forth there will be no more deducable deductions." Presumably, some number of deductive steps in the future, with enough paths considered, would lead to the deduction of deduction, or else it would have to be assumed as an axiom.

Otherwise, it can be a self-referential theorem, or definition.

---

Since this hypothetical proof is a representation, let us define a pattern representation of 1s and 0s, a Turing-complete representation system, to describe it $k = \langle 0, 1 \rangle^n$.

More specifically, let us use, with Qualia, our representation of 1s and 0s, some undefined representation, to do so: 

$\Omega = \lim_{i, n \to +\infty} \mathrm{I}_i^n(\emptyset)$.

Since it is ongoing, we may define a deductive present $n = t$. 

And now we may redefine the present: $n = t + 1$.

And so on, denoting the current derivation step $n$. ($n = t + 2$)

Thus, our recursive representation, $\Omega$, is finite, composed $n$ times.

---

Since $\Omega$ represents deduction, all that is left is to draw an equivalence between $\Omega$ and our reality within which this mathematical system is taking place.

Self-causality demonstrates how our reality could create itself, and thereby this proof, with $\Omega$ as the representation, may be a hypothetical reference to the observable universe's meta-reality. To conclude the proof, we would need a reality, such as our own, in physical matter, to physically point to, not the mathematical symbol $\Omega$. However, by analogy, we can do just that.

Let's distinguish two Omegas. The Omega in this proof, $\hat{\Omega}$, that is a representation. And, hypothetically, the referent Omega that exists outside of the proof from which we, as provers, follow the mathematical steps of deduction: $\Omega$, physical reality.

We can now define $\hat{\Omega}$ as a physics model and aim to deduce $\hat{\Omega} = \Omega$ by sampling $\hat{\Omega}$ as a sufficiently probable physics model. This is the process of physics:

$\mathbf{P}((y, h^{(n)}) \sim \mathrm{R}^n(x, h^{(0)}) \vert y)$

where $\mathrm{R}$ is a recursive dynamics model and a random variable, $h$ is the hidden state (the non-observable universe) at any time point up to some conceivable horizon (in order to make $\mathrm{R}$ defined), composed $n$ times. $x$ is a singled out cause of interest[^1], $y$ is the observable universe.

---

If an $\mathrm{R}$ exists that is both true to observable reality and that this proof derives to, with observable probability in the infinitum, by its derivation observable bounds, as per the standard scientific method and evidence (p-values, null hypotheses, and correlations of model prediction) we have then concluded our proof, and proved the origin of the universe and its mechanism. 

First, let's be concrete about what these processes are.

**Physics:**

$\mathbf{P}((y, h^{(n)}) \sim \mathrm{R}^n(x, h^{(0)}) \vert y)$

where $\mathrm{R}$ is a recursive dynamics model and a random variable, $h$ is the hidden state (the non-observable universe) at any time point up to some conceivable horizon (in order to make $\mathrm{R}$ defined), composed $n$ times. $y$ is the observable universe.

**Causal reasoning:**

$\mathbf{P}((y, h^{(n)}) \sim \mathrm{R}^n(x, h^{(0)}) \vert y, \mathrm{R})$

$x$ is the cause, $y$ is the effect, under some dynamics system $\mathrm{R}$.

**Axiomatic math:**

$\mathbf{P}((y, h^{(n)}) \sim \mathrm{R}^n(x, h^{(0)}) \vert h^{(n)}, n \in \mathcal{N}, \mathrm{R}, x, h^{(0)})$

where $\mathrm{R}$ is the rules of math. $y$ is a theorem or theorem set, $x$ is an axiom or axiom set. $\mathrm{R}$ is Turing-complete due its rewritable memory state $h$. Ordinarily, $\mathrm{R}$'s rules are deterministic, a side effect being that the probability of a theorem $y$ is also deterministic, $1$ or $0$. 

Non-deterministic math, e.g. an "Occam's razor" "theorem", we will refer to as epistemological math, rooted in belief.

**Belief:**

$\mathbf{P}(B \vert E) = \frac{\mathbf{P}(E \vert B)\mathbf{P}(B)}{\mathbf{P}(E)}$

Random variables are also useful to defining implications, causal derivation steps, and theorem-deduction steps, which are relevant to the end goal of this proof:

**Theorem-deduction steps:**

Random variables may be also expressed as relating other random variables, for example

$\mathbf{P}(x > y)$.

Furthermore, they can be used to express deduction steps. Transitivity of the greater-than inequality for example, using conditionals to specify the valid axioms or theorems $(x > y, y > z)$ that would imply the prior $x > z$.

$\mathbf{P}(x > z \vert x > y, y > z) = 1$

They may even be cross-referential:

$\mathbf{P}(w > z \vert w > x, \mathbf{P}(x > z \vert x > y, y > z) = 1) = 1$,

Treating each other as random variables.

Could such an ontology form the basis of a data structure to represent $R, h^{(0)}$ in axiomatic math? Using deterministic conditionals with probabilities $1$ as proof steps and a defined set of initial conditionals and beliefs (random variables), it seems so.

---

Furthermore, it can generalize to a new type of math where proof steps can be epistemological, non-deterministic beliefs applied to other beliefs to quantify a looser proof. This is standardly done in physical sciences with the use of p-values, and we draw a formal unambiguous connection between that to AI and reasoning generally, keeping these notations and formalities that tie together the larger sciences.

Physics, causality, and math have utility and correlative predictiveness to our memories and senses, but beyond observing what's in front of us, these established beliefs are symbolic references within the brain, and the referents are memories, observations, and beliefs. As René Descartes derived with "*cogito, ergo sum*": "I doubt, therefore I am," we can further deduce inwardly. If I may: 

"I observe, therefore I am observing, therefore I am. 

I observe many referents to my observation, including memories, feelings, and viscera. There's also belief. I believe X, Y, Z. I justify X, Y, Z by reasons, another element of belief, X', Y', Z'."

Each step is deeper into the psyche.

Physics, causality, and math are beliefs. 

Philosophy includes these meta-beliefs as well as others.

Perhaps, philosophically speaking, philosophy is the random variable set encompassing all random variables:

**Philosophy:**

$\langle B \vert (B \in \Omega) \sim \mathbf{P}(B \in \Omega) \rangle$,

though to define it as such would contradict that definition since a random variable set encompassing all random variables would have to be contained within itself, making the definition self-referentially undefined. This would be analogous to defining a word in a dictionary by some other words plus itself. Turtles-all-the-way-down is distinct from cyclicality. Gödel's theorem pertains to this. It says within a self-referential proof, [to be continued...]

---

By defining philosophy as a random variable set, we permit the question, "What is a random variable?" even as the set is defined as one of all random variables. Random variables include probability distributions, but what else might they include? That philosophical question remains a part of this recursive set non-definition.

Is the Schrödinger wave equation for example a random variable? Yes, it can be expressed as one.

What about art? It can be. A generator in a GAN is evidence and the mechanical properties of the brain suggest that it is.

What about consciousness? Ah, that's where no other math or language except philosophy can broach! And indeed the only way to do it is from the lens of belief and probability. This question itself can be expressed as: $P(c \in \Omega)$.

---

We have concluded our proof when we have shown our **theorem deduction steps**, random variables composing random variables, are equivalent to $\hat{\Omega}$, represented by Qualia, are models of $\Omega$.

---

Let's address the elephant in the room.

The teleology, as to why it is the way it is, is dismissed in favor of the causal “how”. How does it transition from point $t$ to point $t + 1$. The standard equation describes this mechanistic process, but does not give a clue as to why that process isn’t something totally different. Its origins can be traced, down to negligible times from origin, at least as far as can be determined by observation, and beyond that the question halts.

We cannot describe the system beyond its observability. We cannot determine where it halts backwards in time, no more than when a computer might halt forward in time given a program. The program can be immeasurably precise in its calculations, but no matter how good the model, the line of sight beyond its execution cannot be observed.  [edit: edit all this]

Within the system of math, it is the same. Gödel showed that a theorem always exists that cannot be proven. He used a self-referential theorem to make this point. Of course, though Gödel did not show this, an external body of math could be introduced to refer to that proof process, but then that external body would need its own external body and so on, resulting in a “turtles all the way down” logic, and naturally that is the best our logic affords to explain the origin of the universe, even with the wisdoms and insight of the Big Bang theory.

In other words, a simple answer as to “why” the universe exists is because another universe produced it. And so on. 

Another is infinite recursion. Our universe ends at the beginning, producing itself upon collapse. The wheel of time.

Religious views have held these ideas for centuries. The universe exists because God created it, the universe rests on the back of a thousand turtles, the universe is a patterned cosmic wheel that starts where it ends (the snake that eats its tail) in infinite cyclic fashion of eternal recurrence, etc.

$\Omega_T = \Omega_0$. (infinite recurrence)

These views have been interpreted by countless religions in countlessly romantic, terrifying, and otherwise characterizations. Nietzsche’s “eternal recurrence” thought experiment presents the notion as terrifying, spawned by a demon invading his nightmares. In Hindu Samsara, in Buddhist karmic wheel, there are similar interpretations.

In fact, there is one that does not have to be so scary. It will be described in an equation that is meant to be optimistic:

$\lim_{t \to +\infty} \Omega_t = \Omega_0$. (conservation theory)

The origin of the universe is thus explained by the infinite recursion of an infinitely horizon’d universe.

In this interpretation, the universe may create itself one day and therefore can exist, but tomorrow remains unknowable and its doom can always be procrastinated.

Nevertheless, in the infinitum, this equation creates the universe, without logical contradiction or a “Turtles all the way down” logic, much as the infinite recursion theory explains it, but without the fears of Samsara, and eternal recurrence. Mathematically, it tracks. It also weighs much less on the soul.

It is still bizarre to fathom why a recurrent self-creation would pop into being, even if it did create itself? 

Besides these 3 cosmogonical explanations, there is no theory within logic that explains the cosmogonical origin of the universe. However, that does not exclude a fourth. The fourth to add to the list, is that beyond this reality of logic, there is one entirely without it in which, for example, those condensed energies at the start of the Big Bang could just magically arise. 

Why did something else not pop into being? Where are those universes, if they exist? Can they connect to ours? What are the odds something so ordered, that can be described by a single standard-model equation, would be what pops into being, if literally anything at all could? Such an ontology of particles in 3D space, in gravitational 4D spacetime, is surreal to give weight to random chance at the start of the Big Bang when the condensed energies were already behaving in suspiciously precise ways, according to suspiciously specific hard-coded laws. Yet beyond that horizon, if there is a beyond, we cannot see.

We can however speculate. 

It is possible the existing laws “evolved” from a hyperreality, without logic, out of the scope of abrupt universes that, due to inconsistencies within their own logics, couldn’t survive. Ours perhaps developed something by random chance that allowed it to, in time, reach a set of laws that today function stably as our known laws of physics, but which were not, at one point, stable.

In this evolution hypothesis, survival can be interpreted as a reality-teleology. One purpose that is consistent with the three logic-based cosmogonic explanations, is the purpose to, eventually, create itself. That would have to be an innate purpose of the universe for it to be able to exist in coincidence with logic, without relying on suspect "turtles all the way down" recurrence or attributing solely to magic. 

Unlike other origin theories, this one provides a argued axiom, premised only on logical causalty. However, all math implicitly makes this causality assumption, in its rules, without stating it as an axiom. 

We can also construct a universe of dual creators, as per causal theories 2 and 3, with the quintessence of causal theory 1. As Yin creates Yang, Yang creates Yin.

Perhaps God is using this universe as a canvas to create Himself.

The limits of observability prevent us from making any conclusions without assuming recognized patterns as laws. Those recognized patterns suggest the existence of causality. Causality, in self-consistency, requires an exteral body to create itself or a cyclic self-creation. Proposed here, is a variation of cyclic cosmogenesis that is mathematically more optimistic.

Curvature of spacetime was originally proposed in general relativity, regarding the motions of mass.

[^1]: Such as cyclical self-deduction.
