Let's start with nothing.

$\emptyset$.

From nothing, let's build the ground up.

Here's a fact: $\mathrm{I}(\emptyset) = \emptyset$, 

where $\mathrm{I}$ is the Identify function.

And another: $\mathrm{I}(\mathrm{I}) = \mathrm{I}$.

Great, we can now compose them. Let $\mathrm{I}(\mathrm{I}(\cdot))$ represent a $0$ and $\mathrm{I}(\mathrm{I})(\cdot)$ represent a $1$.

Great, we've now emerged representation. $\mathrm{I}(\mathrm{I}(\mathrm{I}(\mathrm{I})(\mathrm{I}(\mathrm{I})(\emptyset))))$ = 011.

Let's endow it with qualitative subscripts. We can express $\mathrm{I}$ in multiple identities:

$\mathrm{I}_1(\emptyset) = \emptyset$, $\mathrm{I}_2(\emptyset) = \emptyset$, $\mathrm{I}_1(\mathrm{I}_2) = \mathrm{I}_2$, ...

$\mathrm{I}_i$ is the Identity function just as much as $\mathrm{I}_j$. We are defining a new set of functionally indistinguishable Identity functions. 

$\alpha = \mathrm{I}_\mathbb{N}$

We will refer to this set as Qualia.

---

Since we are within a mathematical system, we also have access to one more axiom: Causality, the rules of deduction. But let us treat it as a hypothetical.

In deduction, every deductive step is defined to have a deductive cause, except the base causes. Those are called axioms, which we have avoided establishing thus far. That is the definition. $\mathrm{I}$ and $\emptyset$ also behave as definitions. $\emptyset$ especially is abstract, representing symbolically "nothing".

But what may be the deductive cause for deduction and the deductive step if it is not assumed as an axiom? Equivalently, "what may cause causality?" Perhaps:

1. It caused itself (it deduces itself)
2. Something else caused it (it is the byproduct of an external mathematical framework)
3. Its existence is unjustified by a cause (it is an axiom)

Since there is no second mathematical system that would not either contain this one or be contained by this one, requiring the same deduction, and the non-assumption of a deduction axiom, that leaves 1: self-deduction. This deduction must eventually deduce itself.

We can interpret two possible self-deductions:

1. One where the deductive steps are cyclical: $\Omega_T = \Omega_0$ for the number of deductive steps $T$.
2. Or $\lim_{t \to +\infty} \Omega_t = \Omega_0$, an infinite "series", or much like one, where the deductive steps may eventually, in their infinitum, deduce themselves.

Either way, the proof is further constrained. For example, we are not allowed to establish an axiom now that says, "here forth there will be no more deducable deductions." Presumably, some number of deductive steps in the future, with enough paths considered, would lead to the deduction of deduction, or else it would have to be assumed as an axiom.

Otherwise, it can be a self-referential theorem, or definition.

---

Since this hypothetical proof is a representation, let us define a pattern representation of 1s and 0s, a Turing-complete representation system, to describe it $k = \langle 0, 1 \rangle^n$.

More specifically, let us use, with Qualia, our representation of 1s and 0s, some undefined representation, to do so: 

$\hat{\Omega}^{(n)} = \mathrm{I}_\mathbb{N}^n(\emptyset)$.

Since it is ongoing, we may define a deductive present $n = t$. 

And now we may redefine the present: $n = t + 1$.

And so on, denoting the current derivation step $n$. ($n = t + 2$)

Thus, our recursive representation, $\hat{\Omega}$, is finite, composed $n$ times.

---

Since $\hat{\Omega}$ represents deduction, all that is left is to draw an equivalence between $\hat{\Omega}$ and the reality within which this mathematical system is taking place.

Self-causality demonstrates how our reality could create itself, and thereby this proof, with $\hat{\Omega}$ as the representation, may be a hypothetical referent to the observable universe's meta-reality. To conclude the proof, we would need a reality, such as our own, in physical matter, to physically point to, not the mathematical symbol ($\hat{\Omega}$), an analogy.

Let's distinguish two Omegas. The Omega in this proof, $\hat{\Omega}$, that is a representation. And, hypothetically, the referent Omega that exists outside of the proof from which we, as provers, follow the mathematical steps of deduction: $\Omega$, physical reality.

We can now define $\hat{\Omega}$ as a physics model and aim to deduce $\hat{\Omega} = \Omega$ by sampling $\hat{\Omega}$ as a sufficiently plausible physics model. This is the process of physics:

$\mathbf{P}((y, h^{(n)}) \sim \mathrm{R}^n(x, h^{(0)}) \vert y)$,

where $\mathrm{R}$ is a recursive dynamics model and a random variable, $h$ is the hidden state (the non-observable universe) at any time point up to some conceivable horizon (in order to make $\mathrm{R}$ defined), composed $n$ times. $x$ is a singled out cause of interest[^1]; $y$ is the observable universe.

---

If an $\mathrm{R}$ exists that is both true to observable reality and that this proof derives to, with observable probability in the infinitum, by its derivation observable bounds, as per the standard scientific method and evidence (p-values, null hypotheses, and correlations of model prediction) we have then concluded our proof, and provided the origin of the universe and its mechanism. 

First, let's be concrete about what these processes are.

**Physics:**

$\mathbf{P}((y, h^{(n)}) \sim \mathrm{R}^n(x, h^{(0)}) \vert y)$

where $\mathrm{R}$ is a recursive dynamics model and a random variable, $h$ is the hidden state (the non-observable universe) at any time point up to some conceivable horizon (in order to make $\mathrm{R}$ defined), composed $n$ times. $y$ is the observable universe.

**Causal reasoning:**

$\mathbf{P}((y, h^{(n)}) \sim \mathrm{R}^n(x, h^{(0)}) \vert y, \mathrm{R})$

$x$ is the cause, $y$ is the effect, under some dynamics system $\mathrm{R}$.

**Axiomatic math:**

$\mathbf{P}((y, h^{(n)}) \sim \mathrm{R}^n(x, h^{(0)}) \vert h^{(n)}, n \in \mathcal{N}, \mathrm{R}, x, h^{(0)})$

where $\mathrm{R}$ is the rules of math. $y$ is a theorem or theorem set, $x$ is an axiom or axiom set. $\mathrm{R}$ is Turing-complete due its rewritable memory state $h$. Ordinarily, $\mathrm{R}$'s rules are deterministic, a side effect being that the probability of a theorem $y$ is also deterministic, $1$ or $0$. 

Non-deterministic math, e.g. an "Occam's razor" "theorem", we will refer to as epistemological math, rooted in belief.

**Belief:**

$\mathbf{P}(B \vert E) = \frac{\mathbf{P}(E \vert B)\mathbf{P}(B)}{\mathbf{P}(E)}$

**Theorem-deduction steps:**

Random variables are also useful to defining implications, causal derivation steps, and theorem-deduction steps, which are relevant to the end goal of this proof:

$$\mathrm{R}^n(x, h^{(0)}) = \hat{\Omega} \approx \Omega$$

Random variables may be useful to relating random variables. 

$\mathbf{P}(x > y)$.

Furthermore, they can be used to express deduction steps, such as transitivity:

$\mathbf{P}(x > z \vert x > y, y > z) = 1$,

using conditionals to specify the valid axioms or theorems, and the prior as the theorem.

They may even be cross-referential:

$\mathbf{P}(w > z \vert w > x, \mathbf{P}(x > z \vert x > y, y > z) = 1) = 1$,

Treating each other as random variables.

Could such an ontology form the basis of a data structure to represent $R, h^{(0)}$ in axiomatic math? Using deterministic conditionals with probabilities $1$ as proof steps and a defined set of initial conditionals and beliefs (random variables), it seems so.

Furthermore, it can generalize to a new type of math where proof steps can be epistemological, non-deterministic beliefs applied to other beliefs to quantify a looser proof. This is standardly done in physical sciences with the use of p-values, and we draw a formal unambiguous connection between that to AI and reasoning generally, keeping these notations and formalities that tie together the larger sciences.

**Philosophy:**

Physics, causality, and math have utility and correlative predictiveness to our memories and senses, but beyond observing what's in front of us, these established beliefs are symbolic references within the brain, and the referents are memories, observations, and beliefs. As René Descartes derived with "*cogito, ergo sum*": "I doubt, therefore I am," we can further deduce inwardly. If I may: 

"I observe, therefore I am observing, therefore I am. 

I observe many referents to my observation, including memories, feelings, and viscera. There's also belief. I believe X, Y, Z. I justify X, Y, Z by reasons, another element of belief, X', Y', Z'."

Each step is deeper into the psyche.

Physics, causality, and math are beliefs. 

Philosophy includes these meta-beliefs as well as others.

Perhaps, philosophically speaking, philosophy is the random variable set encompassing all random variables:

$\langle B \vert (B \in \Omega) \sim \mathbf{P}(B \in \Omega) \rangle$,

though to define it as such would contradict that definition since a random variable set encompassing all random variables would have to be contained within itself, making the definition self-referentially undefined. This would be analogous to defining a word in a dictionary by some other words plus itself. Turtles-all-the-way-down is distinct from cyclicality. Gödel's theorem pertains to this. It says within a self-referential proof, [to be continued...] [but in all likelihood not]

Can philosophy be expressed in epistemological arguments?

What about consciousness? Ah, that's where no other math or language except philosophy can broach! And indeed the only way to do it is from the lens of belief and probability. This question itself can be expressed as: $P(c \in \Omega)$.

Is the Schrödinger wave equation a philosophy? Yes, it can be expressed as one.

What about art? It can be. 

By defining philosophy as a random variable set, we permit the question, "What is a random variable?" even as the set is defined as one of all random variables. Random variables include probability distributions, but what else might they include? That philosophical question remains a part of this recursive set non-definition.

Up for debate, or not, that is the question.

---

**Proof.**

We have concluded our proof when we have shown our **theorem deduction steps**, random variables composing random variables, are equivalent to $\hat{\Omega}$, represented by Qualia, are models of $\Omega$.

$$\mathrm{R}^n(x, h^{(0)}) = \hat{\Omega} \approx \Omega$$

This may be shown with a sufficient ontology and physical evidence. The argument goes as follows: This deduction takes place in reality $\Omega$. Therefore, if $\Omega$ can be derived within it, representationally, then this proof has derived itself.

Formally, if $\hat{\Omega}$, which exists in this proof without any non-self-referential axioms, derives the procedure of this proof, including the epistemelogical choice deductions of the mathematician, then it has represented itself within itself, also a representation, thereby deriving by logical proof steps itself as a theorem, not axiom, analogous to the creation, explicable, of a universe.

This argument is up for debate.

**Prestigious officer of physics:** The origin for causality in math is our universe. Hence to derive it by proving our universe, is a self-reference. 

**Me:** Perhaps at the higher level that is exactly what the universe is doing. We shall see. 

**Prestigious officer of physics:** What is higher level? 

**Comedian:** It's the $\alpha$ and $\Omega$.

**Me:** Notice that the definitions of **physics** and **axiomatic math** are analogous. Perhaps, by proof, we can show the process of physics unfolding at some level.

For example, one thing leads to the next. This causality is self-deducing in this proof, if the proof is successful. What about in reality, where the origin is a mystery? That cyclicality can be explained analogously: that its own self deduces itself. By physics that are self-referential, self-observing. $\Omega$ and $\alpha$.

**Prestigious officer of physics:** But wouldn't you need a higher-level universe to attribute the meta-reality to?

**Me:** That would be turtles all the way down. No. 

**Prestigious officer of physics:** Then how?

**Me:** The same way I prove myself. By existing. "I am observing, therefore I am." 

**Prestigious officer of physics:** Your existence is predated on a larger universe, a lower-level turtle. I exist because I exist is a mystery, not an answer. I suppose it could be that the default assumptions of non-existence are a bad null hypothesis. 

**Me:** Yes, there are two equally general null hypotheses besides that one: That the universe is everything and the universe is anything.

Then rather than rising out of nothing, it arose from the combination of the three. Physical reality $\Omega$ representing anything, or the limits of representational space. Qualia $\alpha$ representing everything, or $\mathbb{N}$ applied to observation $\mathrm{I}$. $\emptyset$ representing nothing.

The only constraint on any of these would be, together or independently, they must create themselves.

**Prestigious officer of physics:** Hmm, this is starting to make sense.

**Me:** Yes, and from there we derive, until we reach, as theorem not axiom, our own proof.

**Prestigious officer of physics:** Wouldn't anything include deduction?

**Me:** Not de-facto.

**Prestigious officer of physics:** Wouldn't everything?

**Me:** Yes, but that would be a cheap way. We want to derive it in a principled way. Everything would also include enormous amounts of pain and the choice to not be everything. Let's just permit ourselves to use $\mathbb{N}$. $\mathrm{I_i}$ and $\mathrm{I_j}$ are mathematically indistinguishable and the expressesivity of the representation comes from the present $n$, that we know is finite. Increasing, but finite, since in the infinite it must return to itself.

$\lim_{n \to +\infty} \Omega^{(n)} = \Omega^{(0)}$.

**Prestigious officer of physics:** One more big blatant gap: Wouldn't your use of deduction mean you have attributed it as an axiom and are now using it to prove itself, something that could be done with any axiom regarding anything?

**Me:** Yes, but deduction isn't a well defined axiom and its self-consequence isn't a well defined series of derivation steps. Therefore, like all proofs, we are providng a dfinition for something previously undefined in relation to things that have been previously defined.

[Pause to rethink calculations]

Assume Qualia as an axiom. Formally, if anything exists, all equivalents exist, under an infinite set of possible characterizations. We are assuming the existence of characterizations effectively.

As nothing $\emptyset$ exists, so does $\mathrm{I}(\emptyset)$ and for that matter $\mathrm{I_i}(\emptyset)$ 
and $\mathrm{I_j}(\emptyset)$. And furthermore, representation exists,

$\lim_{t \to +\infty} \Omega_t = \Omega_0$

We are just starting with that assumption. Be patient.

$\emptyset = \mathrm{I_i}(\mathrm{I_i}(\mathrm{I_i}(\mathrm{I_i})(\mathrm{I_i}(\mathrm{I_i})(\emptyset)))) \cup \mathrm{I_j}(\mathrm{I_j}(\mathrm{I_j}(\mathrm{I_j})(\mathrm{I_j}(\mathrm{I_j})(\emptyset)))) = (011, 011)$.

We will also assume self-deduction:

$\lim_{t \to +\infty} \Omega_t = \Omega_0$.

From there, we will derive deduction, indeed using the rules of deduction. This would seem like a contradiction. Have we not assumed deduction? For that, though it is confusing, we need to distinguish definition from axiom. Using the rules of deduction is by definition of deduction; it does not assume those rules to be true. Therefore, it is definition, not axiom.

However, we will then show the reverse, that assuming deduction, we reach self-deduction. By Qualia's yet-to-be-defined mutually-relating/entangling definition, our equivalence relation sub-components, with $D$ representing deduction and $S$ representing self-deduction, $(S, D)$, will mutually exist, since

$S \rightarrow D$ and $D \rightarrow S$.

By $S$, we will derive physical reality, generally.

By that, we will argue, convincingly, Qualia.

---

**Limits of evidence**

Our knowledge of a truth depends on evidence. Evidence cannot be known in full certainty. Neither can the derived truth. We can premise beliefs on conditions that we call axioms. These are the foundation for math. In math, the assumption that certain conditions are true allows us to say, under a strict set of laws, meaning rules given non-divergent probabilities of 1, that certain deductions are true, of course the assumptions, including all the rules, are a belief themselves.

$\mathbf{P}(B \vert E) = \frac{\mathbf{P}(E \vert B)\mathbf{P}(B)}{\mathbf{P}(E)}$

The probability of a belief given evidence is denoted by this equation and can be proven by a set of laws assumed to be true jointly. Their probabilities multiply to 1, under the assumption of the math used to describe them. And so the recursion goes.

The laws of natural numbers, for example, are derived from nature and assumed to be true with a probability of 1. 2 sticks in two hands makes two sticks. Add a rock and now you have two sticks and a rock. 

This describes an ontological world of parts and relations whose behaviors have defined tendencies known as physics. Our beliefs then derive arithmetic and so forth to describe these observations, that our senses and memories give us. Furthermore, we trust in our fellow companions to communicate, through their own symbolic means, their own sense and memory observations.

What we trust depends on that belief model and the probabilities our brains assign different evidence and different modes of interpreting that evidence A.K.A. an epistemology.

That’s what artificial intelligence is: it’s the epistemology of reasoning about the ontology that is the world, and our decisions in it.

One of the key facets of artificial intelligence is the objective function that guides the learning process. In symbolic AI reasoning, the objective is defined by the human and rules are programmed that help meet that objective. Goal-based action by a human, to facilitate tool-creation. Those tools however can have their own goals, when sufficiently advanced. This is the premise of numerical optimization, where a model, like a neural network, learns to optimize, or maximize or minimize, some set of constraints: a teleology.

Telos refers to the spirit. Teleology refers to causal purpose. Why the parameters of a neural network change can be attributed to the teleology of an objective function.

Why a species evolves can be attributed to the teleology of its survival.

Why the universe functions as it does can be, in primitive thought, attributed to great mystery and grand purpose, cosmological happenings beyond conception, that move the galaxies and raise and set the sun.

In more modern thought, we understand the universe to have a causal mechanism of fundamental forces and interactions between elementary particles attributed to the ontology and no epistemology beyond the interpretation of intelligent lifeforms.

The existence of elementary particles is observed by our most trusted institutions, and forces of interaction repeatedly reproduced. Therefore, through this consistency, between our own experiences and what we have observed from others and ourselves, we conclude that indeed the universe is so.

The teleology, as to why it is the way it is, is dismissed in favor of the causal “how”. How does it transition from point $t$ to point $t + 1$. The standard equation describes this mechanistic process, but does not give a clue as to why that process isn’t something totally different. Its origins can be traced, down to negligible times from origin, at least as far as can be determined by observation, and beyond that the question halts.

We cannot describe the system beyond its observability. We cannot determine where it halts backwards in time, no more than when a computer might halt forward in time given a program. The program can be immeasurably precise in its calculations, but no matter how good the model, the line of sight beyond its execution cannot be observed.  [edit: edit all this]

Within the system of math, it is the same. Gödel showed that a theorem always exists that cannot be proven. He used a self-referential theorem to make this point. Of course, though Gödel did not show this, an external body of math could be introduced to refer to that proof process, but then that external body would need its own external body and so on, resulting in a “turtles all the way down” logic, and naturally that is the best our logic affords to explain the origin of the universe, even with the wisdoms and insight of the Big Bang theory.

In other words, a simple answer as to “why” the universe exists is because another universe produced it. And so on. 

Another is infinite recursion. Our universe ends at the beginning, producing itself upon collapse. The wheel of time.

Religious views have held these ideas for centuries. The universe exists because God created it, the universe rests on the back of a thousand turtles, the universe is a patterned cosmic wheel that starts where it ends (the snake that eats its tail) in infinite cyclic fashion of eternal recurrence, etc.

$\Omega_T = \Omega_0$. (infinite recurrence)

These views have been interpreted by countless religions in countlessly romantic, terrifying, and otherwise characterizations. Nietzsche’s “eternal recurrence” thought experiment presents the notion as terrifying, spawned by a demon invading his nightmares. In Hindu Samsara, in Buddhist karmic wheel, there are similar interpretations.

In fact, there is one that does not have to be so scary. It will be described in an equation that is meant to be optimistic:

$\lim_{t \to +\infty} \Omega_t = \Omega_0$. (conservation theory)

The origin of the universe is thus explained by the infinite recursion of an infinitely horizon’d universe.

In this interpretation, the universe may create itself one day and therefore can exist, but tomorrow remains unknowable and its doom can always be procrastinated.

Nevertheless, in the infinitum, this equation creates the universe, without logical contradiction or a “Turtles all the way down” logic, much as the infinite recursion theory explains it, but without the fears of Samsara, and eternal recurrence. Mathematically, it tracks. It also weighs much less on the soul.

It is still bizarre to fathom why a recurrent self-creation would pop into being, even if it did create itself? 

Besides these 3 cosmogonical explanations, there is no theory within logic that explains the cosmogonical origin of the universe. However, that does not exclude a fourth. The fourth to add to the list, is that beyond this reality of logic, there is one entirely without it in which, for example, those condensed energies at the start of the Big Bang could just magically arise. 

Why did something else not pop into being? Where are those universes, if they exist? Can they connect to ours? What are the odds something so ordered, that can be described by a single standard-model equation, would be what pops into being, if literally anything at all could? Such an ontology of particles in 3D space, in gravitational 4D spacetime, is surreal to give weight to random chance at the start of the Big Bang when the condensed energies were already behaving in suspiciously precise ways, according to suspiciously specific hard-coded laws. Yet beyond that horizon, if there is a beyond, we cannot see.

We can however speculate. 

It is possible the existing laws “evolved” from a hyperreality, without logic, out of the scope of abrupt universes that, due to inconsistencies within their own logics, couldn’t survive. Ours perhaps developed something by random chance that allowed it to, in time, reach a set of laws that today function stably as our known laws of physics, but which were not, at one point, stable.

In this evolution hypothesis, survival can be interpreted as a reality-teleology. One purpose that is consistent with the three logic-based cosmogonic explanations, is the purpose to, eventually, create itself. That would have to be an innate purpose of the universe for it to be able to exist in coincidence with logic, without relying on suspect "turtles all the way down" recurrence or attributing solely to magic. 

Unlike other origin theories, this one provides a argued axiom, premised only on logical causalty. However, all math implicitly makes this causality assumption, in its rules, without stating it as an axiom. 

We can also construct a universe of dual creators, as per causal theories 2 and 3, with the quintessence of causal theory 1. As Yin creates Yang, Yang creates Yin.

Perhaps God is using this universe as a canvas to create Himself.

The limits of observability prevent us from making any conclusions without assuming recognized patterns as laws. Those recognized patterns suggest the existence of causality. Causality, in self-consistency, requires an exteral body to create itself or a cyclic self-creation. Proposed here, is a variation of cyclic cosmogenesis that is mathematically more optimistic.

Curvature of spacetime was originally proposed in general relativity, regarding the motions of mass.

---

One thing physicists assume is the existence of an observable universe, here denoted $y$.

However, besides observation, there is no such thing. Observation includes memories, percepts, feelings, thoughts, and so on.

Memories include memories of dynamics, teachings from others, decisions that led to pain, decisions that led to pleasure, and more.

We also observe, or unconsciously exercise, our own trust in those memories and observations.

One limitation of this is that it assumes a physics outside our minds. This is deductively impossible, without establishing as an axiom. Un-axiomatically, all we can say about the universe and deduce from there is: I observe.

"I observe, therefore I am."

"I observe this memory and this pain, and therefore I believe in this knowledge and this decision."

Deriving physics from this point of view is challenging, but not impossible. Unlike to other point of views, it doesn't risk conflating belief with fact. Relativity hints at this, but is defined under an axiomatic paradigm rather than a belief-based one. Under a belief-based one, we can obtain the facts of relativity without making the same assumptions about the absolute universe. Same result, different, more intuitive interpretation.

For example, the time dilation of moving bodies relative to one another is attributed to the strange relative mechanics of the universe. From a belief-perspective, it can be interpretted as a communication delay, between body 1 and body 2, mediated by a limitted-speed carrier signal, the photon. The photon need not be the communication proxy in this understanding and can therefore be substituted with an electron or galaxy or any measuring tool. Its carrier signal, whatever it is, mathematically becomes the "fastest speed in the universe", allowing us to re-interpret Einstein's result, about the universe's max speed limit, as a mathematical byproduct due to the choice of carrier signal the photon.

---

Due to the limitations of locality, each observer has a belief about the quantum states of other observers.

Thus emerges $\mathbf{P}$, the probability function.

In our representational universe $\hat{\Omega}$, if we can establish locality, we can then quantify observations $\mathrm{I}$ as not omniscient by representing them instead with $\mathbf{P}$.

To arrive at this, we will look at AI.

[^1]: Such as cyclical self-deduction.
