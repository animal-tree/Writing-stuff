Definitions:

**Occurrence.** A time and location-defining-region.

**Elementary body.** A body whose only body is itself.

**Body.** A proximal occurrence of elementary bodies in time and location. (identity link)

**Coincidence.** A proximal occurrence of one or more bodies in time or location or identity. (evidential link)

**Coincidence of coincidences.** A proximal occurrence of coincidences in time or location or identity. (causal link)

**Hypothesized scientific cause.** Consistent coincidences of coincidences. (general scientific causal link)

**Hypothesized temporal scientific cause.** Consistent coincidences of coincidences in time, but not necessarily location, of specific identities. (standard scientific causal link)

**Consistency.** A ratio. The number of measurements a hypothesized scientific cause agrees with in proportion to the number of measurements a hypothesized scientific cause does not agree with. (likelihood of scientific model)

**Agreement.** The proximity between a measured body or coincidence and a hypothesized body or coincidence. (coincident predictiveness)

**Proximity.** A number between two locations, or between two points in time, designating their coordinate distance respectively; or between two identities, designating their dissimilarity of (a) occurrence, (b) body-composition, and/or (c) coincident-interaction; or between an identity and a location and/or time, designating the identity’s dependence on that location and/or time; or between two coincidences, designating the dissimilarity of their constituent bodies’ locations, times, and/or identities. (combinatorial, hierarchal, relational graph)

**Hypothesized scientific model.** Assignment of proximity scores between pairs of bodies and/or coincidences. (forces and interactions, and bodies, allowing the determination of consistency and therefore cause and effect)

**Temporal effect.** The temporally-later of at least one of the coincidences in a hypothesized temporal cause. (measurement)

**Predicted effect.** The deduction of a temporal effect from a hypothesized scientific model based on coincident temporally-later proximities to measured bodies and/or coincidences. (modeling)

**Ambiguity resolution.** A hypothesized scientific model can have multiple ways of prioritizing proximity between bodies and/or coincidences. For example, what makes two coincidences more proximal? Their constituent bodies’ locations and times, or their constituent bodies identities, or all three evenly? If you run into somebody you know right after thinking about them, that is a coincidence between a body and another coincidence: the body of your neurological process about another body, and the coincidence of your two bodies being at the same location. The identity of your neurological process (in your body, and as being about the other body) is proximal to the two identities of each of the two bodies. Thus, that body and coincidence consist of identities whose proximity is objectively more proximal than if they referred to the identities of the bodies of two different people, making it objectively a “bigger coincidence.” However, without a consistency of such coincidences — in location, time, and/or identity — a hypothesized scientific cause cannot be attributed to the coincidence. And without a consistency of such coincidences in the same chronological order and between the same two bodies — perhaps only varying in location — a hypothesized temporal scientific cause cannot be attributed to the coincidence.

However, these proximity scores are not provided by nature directly. A hypothesized scientific model defines them, but a hypothesized scientific model might be more right or less right, and in order to resolve the accuracy of a hypothesized scientific model, given that as an epistemological objective, a process is needed. (evolution of null hypothesis)

**Hypothesis accuracy.** Number and certainty of measurements, maximization of the consistency ratio. (null hypothesis criteria)

**Scientific knowledge-acquisition.**

1. Hypothesized scientific model.
2. Measurements.  
3. Updated hypothesized scientific model based on consistency between proximity of measured coincidences.

In practice, which measurements are conducted must be prioritized due to resource and time constraints, for example by estimates of how certain or uncertain existing available data is, and the availability of the data, and weighing consistency ratios based on one’s estimated certainty of the corresponding data regarding those measurements.

**Is prediction necessary?**

Note: The big heresy here is that “prediction” doesn’t necessarily come into the picture at all. High-certainty data collected entirely accidentally is just as valid as equally-certainty data collected through the traditional scientific method process of predicting and verifying predictions first.

“Germs cause disease”

1. Microscopes measure specific microorganisms (specific microorganisms that are actually later defined as “germs”) in diseased persons.
2. The diseased person is believed to be diseased based on reported wellbeing, visible symptoms, or measurements such as blood tests or urine samples.
3. This coincidence of measurement (1 and 2) is consistently measured with diseased persons. Sometimes a sequence of transformations is consistently measured as well that transforms germs to disease (1 to 2).

Somehow, we conclude that 1 is the cause, 2 is the effect, and 3 is the justification.

To recap, the scientific method is:

- Characterizations (observations, definitions, and measurements of the subject of inquiry)
- Hypotheses (theoretical, hypothetical explanations of observations and measurements of the subject)
- Predictions (inductive and deductive reasoning from the hypothesis or theory)
- Experiments (tests of all of the above)

(Source: “Scientific Method” - Wikipedia)

At first glance, these 4 bullets are actually quite different from the 3 measurement practices (knowledge-acquisition kernel) described earlier that determine the scientific knowledge-acquisition (epistemological) process that allows us to conclude that “germs cause disease.”

First let’s deconstruct why they appear different and show that the second (the scientific method) depends necessarily on the first (consistent coincident measurement, or “coincidence”).

Interestingly, the 3 steps are not a scientific method:

- Characterizations: person as diseased - step 2. 
- Hypotheses: existence of disease - step 2.
- Predictions: “microscope measurement would coincide disease with a potential cause” - an incentivizing motive for conducting step 1; however, step 1 could be plausibly conducted by accident, as is often the case for discoveries in science. Thus not included in the knowledge-acquisition kernel.
- Experiment: microscope measurement - step 1.  Result: existence of germs - step 1. Upon reproduction or across other such microscope measurements, same result - step 3. Perhaps a transforming sequence is measured repeatedly as well - step 3.

Those original 3 steps didn’t explicitly include a prediction. However, upon discovery of the germs, future experiments may now perhaps predict “germs coincide with disease”, or, also possible, stumble onto the same findings by accident.

Hypothetically, if N experiments stumbled onto the same findings by accident, taking the limit of N to infinity, would a prediction be necessary to know scientifically the conclusion of step 3? The answer is no. That’s why the knowledge-acquisition kernel of cause-effect-coincidence is perhaps more general to science scientifically. 

In reality, given already N to infinity: a purposeful experiment which follows a purposeful prediction, is redundant and provides no information gain compared to the existing data, except perhaps on the role of purpose/human-intent in influencing the measurement. In the study of consciousness and wave-particle properties in quantum mechanics, this may be relevant, arguably. However, let’s look into that a bit closer as well to make sure we’re not conflating measurement intent and measurement bias.

If you guess that such a caveat would be such a conflation, you are right. If the measurement is carried out identically, with or without intent, and the result is the same, then intent is not relevant and is redundant. In quantum physics, detectors are used to measure which slit a particle may or may not have gone through. When the detector is active, a different pattern appears on the projection screen than if the detector is inactive, independent on the physicist’s intents or predictions.

Same with the microscope. If one were to investigate a sick person’s body with a microscope “for fun”, and hundreds others did the same and accidentally found measurements of germs, an additional replication of that experiment would psychologically add confidence to the experimenter, but data-centrically provide no information gain and would be redundant. 

That is, unless intent were a causal factor. In psychology experiments and sociology, this often may be the case, where intent is part of the measuring “device” Thus a measurer’s intent or even knowledge that a measurement or experiment is being conducted can influence their measurement. In this case, there is an extra bias that has to be accounted for, making the experimental measurement actually less reliable than in-the-wild accidental stumblings, unless that bias is what’s secretly being measured. 

A prediction can at best be a bias, at worst be redundant. If it’s a bias, then at least we learn something about the nature of prediction. If it’s redundant, then scientifically its value may be zero but it can be attributed value for the subjective, psychological confidence of *control* it gives to scientists. “I have done this intentionally!” rather than “this is caused by this.”

**What about a hypothesized scientific model that can account for hypothesized scientific causes?**

Note: Another heresy is that the standard scientific causality is defined as a special case of causality. While the standard model of physics can somewhat hypothesize about scientific temporal causes, it hasn’t much scratched the surface of non-local synchronous causes or causes whose identities are not as strictly proximal. These are called synchronicities and have been measured, though without demonstrated predictive power, in “datasets” documented throughout books, tomes, and anecdote.

In quantum physics there are believed to be many non-local effects and entanglements that aren’t strictly speaking temporally causal. 

Why our coincidence fixation is dependent on temporal and identity synchronicity/coincidence, and not a looser combination of location, time, and identity, is unjustified.

In my opinion, a 90% proximity between 10 coincidences in time and location, and only a 60% proximity in identity, is just as strong a form of coincidence as a 100% proximity between 10 coincidences in identity, 80% in time, and 2% in location.
